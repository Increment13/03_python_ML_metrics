{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "596f29d5-b01b-4fba-9911-c4d3c93a3828",
   "metadata": {},
   "source": [
    "# Preparing features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455eacb-0bec-451d-89f8-90710b3c743f",
   "metadata": {},
   "source": [
    "<img src=\"./pict/MLmem.jpg\"  \n",
    "  width=\"600\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad451e0-9e26-4a43-a72b-825d3b305ad2",
   "metadata": {},
   "source": [
    "To predict class, we turn to the familiar logistic regression.\n",
    "\n",
    "Logistic regression is suitable for classification problem. For example, as we have, when there is a choice between two categories - whether an insurance payment will be required or not.\n",
    "Let's try to train our model. Do you think it will be possible to do this using raw data? Let's take a risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "735f7c2c-9913-46d7-9c23-b93be88df164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data = pd.read_csv('./data/travel_insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4a35553-6ec6-4a86-902e-33e4e3e4b8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>Agency Type</th>\n",
       "      <th>Distribution Channel</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Comprehensive Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>186</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>9.57</td>\n",
       "      <td>F</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Comprehensive Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>186</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>9.57</td>\n",
       "      <td>F</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>65</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>-49.5</td>\n",
       "      <td>29.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>60</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>-39.6</td>\n",
       "      <td>23.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>79</td>\n",
       "      <td>ITALY</td>\n",
       "      <td>-19.8</td>\n",
       "      <td>11.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Agency    Agency Type Distribution Channel                     Product Name  \\\n",
       "0    CBH  Travel Agency              Offline               Comprehensive Plan   \n",
       "1    CBH  Travel Agency              Offline               Comprehensive Plan   \n",
       "2    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "3    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "4    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "\n",
       "  Claim  Duration Destination  Net Sales  Commision (in value) Gender  Age  \n",
       "0    No       186    MALAYSIA      -29.0                  9.57      F   81  \n",
       "1    No       186    MALAYSIA      -29.0                  9.57      F   71  \n",
       "2    No        65   AUSTRALIA      -49.5                 29.70    NaN   32  \n",
       "3    No        60   AUSTRALIA      -39.6                 23.76    NaN   32  \n",
       "4    No        79       ITALY      -19.8                 11.88    NaN   41  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73846cf4-f928-4afc-a00b-f9403acce3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data, test_size=0.25, random_state=12345)\n",
    "\n",
    "features_train = train.drop('Claim', axis=1)\n",
    "target_train = train['Claim']\n",
    "features_valid = valid.drop('Claim', axis=1)\n",
    "target_valid = valid['Claim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b3bcf18-0ed8-4472-a49d-5cc5a178c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression()\n",
    "# model.fit(features_train, target_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2e26b-e8ff-467c-ab9a-88f75254d6dc",
   "metadata": {},
   "source": [
    "Now you can say: “And I said/said!” Indeed, a mistake.\n",
    "\n",
    "Why did this happen?\n",
    "\n",
    "Logistic regression calculates category membership using a formula consisting of features. They can only be numerical. Our data also contained categorical features - this was the mistake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f555e37-51f0-4c47-b4f8-e20465fbb2f6",
   "metadata": {},
   "source": [
    "## Direct encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c022d2d8-a5ae-4158-be1b-0262e4dc9901",
   "metadata": {},
   "source": [
    "The technique of direct coding, or mapping (One-Hot Encoding, OHE) will help convert categorical features into numerical ones.\n",
    "\n",
    "We will explain the principle of One-Hot Encoding using the values of the Gender attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad325c-cc19-4760-9fb7-bf86044a8afb",
   "metadata": {},
   "source": [
    "For each value of the Gender attribute (F, M, None), a column is created:\n",
    "    \n",
    "- Gender_F\n",
    "- Gender_M\n",
    "- Gender_None (no gender data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a77154-4a5c-49b2-86ae-f2d9e26b1918",
   "metadata": {},
   "source": [
    "<img src=\"./pict/10.png\"  \n",
    "  width=\"600\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08608506-ed66-444e-b919-95ae6b60e806",
   "metadata": {},
   "source": [
    "Let's summarize. Using the OHE technique, categorical features are converted into numerical ones in two stages:\n",
    "- A new column is created for each characteristic value;\n",
    "- If the category suits the object, it is assigned 1, if not - 0.\n",
    "\n",
    "New characteristics (Gender_F, Gender_M, Gender_None) are called dummy-variable.\n",
    "\n",
    "For direct coding, the pandas library has a function `pd.get_dummies()` (“get dummy variables”)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4746f6-24df-462f-a467-c7fcc628dfd5",
   "metadata": {},
   "source": [
    "## Dummy trap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b3268-b32d-41e8-a3e1-43b11692a062",
   "metadata": {},
   "source": [
    "With direct coding, things are not so simple. When there is too much data, you can fall into the trap of bogus features. We'll tell you how to avoid getting into it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1d436-0fc2-4272-b803-3e426a83545e",
   "metadata": {},
   "source": [
    "To apply for a US visa, you need to prove that you have money. You decided to play it safe, so you took a bank account statement, a certificate from work, and 2-personal income tax. Although the visa center only needs two documents.\n",
    "\n",
    "Your model doesn’t really need extra information either. If you leave everything as is, it will be more difficult for her to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad323d-28f1-487e-b1bf-d1b2170ed75c",
   "metadata": {},
   "source": [
    "Three new columns have been added to the table. Since they are strongly related to each other, we will remove one without regret. You can restore the column using the remaining two. This way we won't fall into a dummy trap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb3f360-b0e7-4752-824f-3ad51e0dae4c",
   "metadata": {},
   "source": [
    "We will remove the column by calling the `pd.get_dummies()` function with the `drop_first` argument.\n",
    "\n",
    "It removes the first column and is passed as `drop_first=True` or `drop_first=False` (True means the first column is reset, False means it is not reset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb7be1-c249-44c1-b113-59f2a5e5de97",
   "metadata": {},
   "source": [
    "When training logistic regression, you may encounter a warning from the sklearn library. To disable it, specify the argument `solver='liblinear'`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffa43eea-f75f-4f3b-a628-3ccbfbf8d434",
   "metadata": {},
   "source": [
    "model = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab6ebd-a388-48d8-bf53-d1a4988b1626",
   "metadata": {},
   "source": [
    "## Ordinal encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30b441-d2bb-4682-a54b-9ab153fe9216",
   "metadata": {},
   "source": [
    "Let's talk about another technique for encoding features in a decision tree and a random forest.\n",
    "\n",
    "If a decision tree asks questions at nodes, does that mean it can also work with categorical features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e0bd52-a93c-4baa-813f-506a6da0fac3",
   "metadata": {},
   "source": [
    "<img src=\"./pict/1.jpg\"  \n",
    "  width=\"1100\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c58db2-5d0b-41b1-b675-34c099672af1",
   "metadata": {},
   "source": [
    "Now let's try to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d884b08b-98e1-4e00-a343-1c4f4b7a0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# tree = DecisionTreeClassifier(random_state=12345)\n",
    "# tree.fit(features_train, target_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e375ea8-a13c-4fe0-b48c-715da51b2237",
   "metadata": {},
   "source": [
    "Error again. Caused by the way the decision tree is trained in the `sklearn` library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76211028-4f3b-4ffe-96b9-4dfa89947a26",
   "metadata": {},
   "source": [
    "How to fix it? A new technique is needed to encode categories expressed in text with numbers - Ordinal Encoding. It works like this:\n",
    "- It is recorded what number the class is coded by;\n",
    "- The numbers are placed in a column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b379458-1875-429a-abed-3cf45fe6b50d",
   "metadata": {},
   "source": [
    "The technique is suitable for feature transformation in decision tree and random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d922a8-644f-448e-a0aa-e06f226981f1",
   "metadata": {},
   "source": [
    "<img src=\"./pict/11.png\"  \n",
    "  width=\"300\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a1f757-aeb9-4135-a67c-5ee2db811c55",
   "metadata": {},
   "source": [
    "The conversion is carried out in three stages:\n",
    "1. Create an object of this data structure."
   ]
  },
  {
   "cell_type": "raw",
   "id": "80d3b4b1-6a97-4e4a-bd28-99e907c7c13f",
   "metadata": {},
   "source": [
    "encoder = OrdinalEncoder() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26edb24e-bf52-412f-be86-84e336678d4f",
   "metadata": {},
   "source": [
    "2. To get a list of categorical features, call the fit() method - as in model training. We pass data to it as an argument."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5daf011-eb12-48a1-89c7-7e289f1979bf",
   "metadata": {},
   "source": [
    "encoder.fit(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f9f1b-8d80-4a0d-9a68-8a13e1039c60",
   "metadata": {},
   "source": [
    "3. Transform the data using the transform() function. The changed data will be stored in the data_ordinal variable."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc00da89-9cab-48e0-bbe6-0dfdab3136fa",
   "metadata": {},
   "source": [
    "data_ordinal = encoder.transform(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b471a70-c2fe-46a9-8a36-278348c81d3b",
   "metadata": {},
   "source": [
    "In order for the code to add column names, we will format the data in the DataFrame() structure:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07fa66c1-a63a-4b71-9fa6-a5a19f55a722",
   "metadata": {},
   "source": [
    "data_ordinal = pd.DataFrame(encoder.transform(data), columns=data.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61e9789-d412-4eb0-bf59-0783f9af6528",
   "metadata": {},
   "source": [
    "If feature transformation is required only once, as in our problem, the code can be simplified by calling the fit_transform() function. It combines the functions: fit() and transform()."
   ]
  },
  {
   "cell_type": "raw",
   "id": "36a9b4b0-7371-4aa1-aca7-016338b963aa",
   "metadata": {},
   "source": [
    "data_ordinal = pd.DataFrame(encoder.fit_transform(data), columns=data.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad9bb83-4c62-4d53-badd-0ea939772f8e",
   "metadata": {},
   "source": [
    "## Coding summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6ebc65-c7fc-4f47-b5e2-9ebdb38f4d89",
   "metadata": {},
   "source": [
    "Let's figure out which encoding to choose and why Ordinal Encoding is not suitable for logistic regression.\n",
    "\n",
    "You were introduced to two techniques for coding categorical variables. To summarize:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d18ac-7823-40c4-a024-8527bf8aae36",
   "metadata": {},
   "source": [
    "1. If all traits are to become quantitative, the OHE technique is suitable;\n",
    "2. When all the features are categorical and they need to be converted into numbers - Ordinal Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a54d8-bbc8-4a07-9b60-8be91fb7ca27",
   "metadata": {},
   "source": [
    "Why is `Ordinal Encoding` not suitable for logistic regression? She tries to calculate everything using a formula. If we are talking about the Age feature, then this is reasonable, but with Gender there are difficulties. For example, adding the values ​​“1” and “0” (“woman” and “man”) and dividing by “2” does not result in “average gender”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44f241-9da2-4292-a236-b1d0bb6dd681",
   "metadata": {},
   "source": [
    "<img src=\"./pict/12.png\"  \n",
    "  width=\"900\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf8b074-2f9b-40ea-8d77-cab9d7a70586",
   "metadata": {},
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d20927-36a5-4f12-aba8-06294f63a363",
   "metadata": {},
   "source": [
    "`Dispersion of a random variable is a measure of the dispersion of the values of a random variable relative to its mathematical expectation`\n",
    "\n",
    "`The square root of the variance is called the standard deviation, standard deviation or standard spread.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ffdf5b-b964-4ba4-9858-c2155aa1d34a",
   "metadata": {},
   "source": [
    "The data has columns: Age and Commission.\n",
    "\n",
    "Let's say the possible age ranges from 0 to 100 years, and the insurance commission ranges from 100 to 1000.\n",
    "\n",
    "The values ​​and their spreads in the Commission column are larger, so the algorithm will automatically decide that this attribute is more important than age. But this is not so: all signs are significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b71854-d5a6-4e68-a927-a1c3517d038a",
   "metadata": {},
   "source": [
    "One of the scaling methods is `data standardization`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579a88d-0f18-40e3-bb6d-777e38d9d30d",
   "metadata": {},
   "source": [
    "Assuming that all features are normally distributed, the `mean` (M) and `variance` (D) are determined from the sample. The characteristic values are converted using the formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b0c1ee-c1fa-4590-9749-fbe9455f541f",
   "metadata": {},
   "source": [
    "<img src=\"./pict/13.png\"  \n",
    "  width=\"600\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb8343-bbf5-4735-a948-afbb5b941d44",
   "metadata": {},
   "source": [
    "The new feature has a mean of 0 and a variance of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de742e4d-75f5-4777-a9c0-16baf3df9046",
   "metadata": {},
   "source": [
    "`sklearn` has a separate structure for data standardization - `StandardScaler`. It is located in the `sklearn.preprocessing` module.\n",
    "Import `StandardScaler` from the library:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10c3c992-9748-43a6-b54c-cd600a5eb3d5",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369457f-a268-4463-9ab0-c6a0493d528c",
   "metadata": {},
   "source": [
    "Let's create an object of this structure and configure it on the training data. Setting is calculating the mean and variance:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "528da5a4-22a6-4828-8afa-3ba5e39ac1f2",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d0ffe5-f6fa-4163-b4b0-da7b5a02871b",
   "metadata": {},
   "source": [
    "We transform the training and validation samples using the transform() function. We will save the changed sets in the variables: features_train_scaled and features_valid_scaled:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77cc5a82-7f97-4a85-92a7-7cf50a6ed568",
   "metadata": {},
   "source": [
    "features_train_scaled = scaler.transform(features_train)\n",
    "features_valid_scaled = scaler.transform(features_valid) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4524b7c-d23e-41cc-b3e1-db6ad5ee22f8",
   "metadata": {},
   "source": [
    "When writing changed features to the source dataframe, the code may raise a `SettingWithCopy` warning. The reason is the behavior of `sklearn` and `pandas`.\n",
    "\n",
    "To prevent the warning from appearing, add the following line to the code:\n",
    "`pd.options.mode.chained_assignment = None`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002112e4-05a1-458e-a887-4d53eac89f0f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "IMPORTANT! Scaling of features should only be done after <b>train_test_split</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1377fd-20c4-4857-a00c-bdab655101f2",
   "metadata": {},
   "source": [
    "# Cheat sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2b9e8-8b2b-49de-9866-487f50fc18ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encoding: getting dummy features\n",
    "pd.get_dummies(df['column'])\n",
    "pd.get_dummies(df['column'], drop_first=True)\n",
    "# drop_first = True - drop the first column (avoiding the dummy trap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cac072-e1f6-4033-894e-6a30bf9e5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "encoder.fit(data)\n",
    "data_ordinal = encoder.transform(data)\n",
    "\n",
    "# adding column titles\n",
    "data_ordinal = pd.DataFrame(encoder.transform(data), columns=data.columns)\n",
    "\n",
    "# automatic learning and conversion\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "data_ordinal = pd.DataFrame(encoder.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb02066-3ff3-4d13-bad3-f5977cf731ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "df_scaled = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a834c-8427-405b-bf05-383a62ab074e",
   "metadata": {},
   "source": [
    "# Accuracy metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c4a71c-f9e0-4984-b42c-14bb1985b11c",
   "metadata": {},
   "source": [
    "Suppose we work in a patent office. They brought us a patent that they had invented a non-invasive method for detecting leukemia in infants. It predicts a newborn's susceptibility to developing leukemia with 98% accuracy.\n",
    "\n",
    "As we will now see, this test is indeed `98%` accurate! And yet it is just as stupid, being a good illustration of why Accurasy is not used to evaluate the accuracy of binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada3b4d-50ee-4b03-8291-6160744859e3",
   "metadata": {},
   "source": [
    "- The patent assumes that the model predicts leukemia if and only the patient's name is Gregory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c39f10-640d-4785-9dca-6c554bb7c214",
   "metadata": {},
   "source": [
    "Let's see how my leukemia test fits into this framework. In 2022 in Ukraine, approximately 3% of babies out of 1000 are given the name Gregory, and the lifetime prevalence of leukemia is 1.4%, or 14 people in every 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0219ca50-c4e3-4453-9ae1-17e4b2322bb5",
   "metadata": {},
   "source": [
    "If we consider these two factors to be mutually independent and apply my \"Gregory means leukemia\" test to 1 million people, then we can expect to see a discordance matrix that looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d21c45-2d8d-4ae6-8abc-e566e037d229",
   "metadata": {},
   "source": [
    "<div class=\"scrollable_content\">\n",
    "    <table cellpadding=\"0\" cellspacing=\"0\" style=\"width: 500px; text-align: center;\">\n",
    "        <thead ><tr>\n",
    "            <th scope=\"col\" style=\"text-align: center;\"></th>\n",
    "            <th scope=\"col\" style=\"text-align: center;\">Leukemia</th>\n",
    "            <th scope=\"col\" style=\"text-align: center;\">Not leukemia</th>\n",
    "            <th scope=\"col\" style=\"text-align: center;\">Total</th>\n",
    "               </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "        <tr>\n",
    "            <td style=\"text-align: center;\">Gregory</td>\n",
    "            <td style=\"text-align: center;\">42</td>\n",
    "            <td style=\"text-align: center;\">4 958</td>\n",
    "            <td style=\"text-align: center;\">5 000</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: center;\">Not Gregory</td>\n",
    "            <td style=\"text-align: center;\">13 958</td>\n",
    "            <td style=\"text-align: center;\">981 042</td>\n",
    "            <td style=\"text-align: center;\">995 000</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: center;\">Total</td>\n",
    "            <td style=\"text-align: center;\">14 000</td>\n",
    "            <td style=\"text-align: center;\">986 000</td>\n",
    "            <td style=\"text-align: center;\">1 000 000</td>\n",
    "        </tr>\n",
    "        </tbody></table><div></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57dfab46-57e3-4070-a282-4a1c084c5f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result 98.11%\n"
     ]
    }
   ],
   "source": [
    "correct  = 42 + 981042\n",
    "total = 42+ 4930 + 13958 + 981042\n",
    "\n",
    "result = correct/total\n",
    "    \n",
    "print('result {:.2%}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f2e46-9f1c-4d0a-9944-b1223e0f84d1",
   "metadata": {},
   "source": [
    "# Balance and imbalance of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71a7e2-5d04-4bb5-abbb-c1e1132b03de",
   "metadata": {},
   "source": [
    "We received a percentage of correct answers close to 100%. But there is no understanding of what is happening. In our problem there is a strong class imbalance.\n",
    "\n",
    "Classes are unbalanced when their ratio is far from 1:1. class balance is observed if their number is approximately equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a4d5a3-63f1-4aaa-84ba-71dbf9b55dc7",
   "metadata": {},
   "source": [
    "<img src=\"./pict/14.jpeg\"  \n",
    "  width=\"400\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df3aa1-d777-478d-a14c-cfb755e8c149",
   "metadata": {},
   "source": [
    "`Accuracy` is not suitable. We need a new metric! But first, a few important definitions.\n",
    "\n",
    "You already know that a class labeled “1” is called positive, and a class labeled “0” is called negative.\n",
    "\n",
    "If we compare these answers with the predictions, we get the following division:\n",
    "- True Positive (TP) and True Negative (TN)\n",
    "- False Positive (FP) and False Negative (FN).\n",
    "\n",
    "Let's summarize. The characteristics \"positive\" and \"negative\" refer to the `prediction`, and \"true\" and \"false\" refer to its `correctness`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ca3c8-e320-44fc-b3c7-45e1e4a14be1",
   "metadata": {},
   "source": [
    "<b>True positives</b> What does true positive (TP) mean? The model marked the object as one, and its real value is also 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c6bb13-f227-404a-98fa-75f4b4e2b182",
   "metadata": {},
   "source": [
    "<b>True Negative</b> If the predicted and actual class value are negative, the response is a true negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c4b2ca-fad0-4fac-81b0-f1e21fc2734b",
   "metadata": {},
   "source": [
    "<b>False Positive</b> Type I errors are false positive responses (FP). They occur when the model predicted “1”, but the actual value of the class is “0”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3769caea-8233-408b-842d-89c32d936095",
   "metadata": {},
   "source": [
    "<b>True positive</b> Error of the second type - false negative responses (FN). False negatives occur when the model predicted “0” but the actual class value is “1”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9cbbb6-af13-4d57-a4a2-ae7c7741cc2a",
   "metadata": {},
   "source": [
    "## Error Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f4d5e-7800-441b-8989-3409b7f4ad1b",
   "metadata": {},
   "source": [
    "What we get:\n",
    "\n",
    "The correct predictions are made along the main diagonal (from the upper left corner):\n",
    "- TN in the upper left corner;\n",
    "- TP in the lower right corner.\n",
    "\n",
    "Outside the main diagonal are erroneous options:\n",
    "- FP in the upper right corner;\n",
    "- FN in the lower left corner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db568f6e-b12b-45a0-980a-1649e00c6021",
   "metadata": {},
   "source": [
    "<img src=\"./pict/15.png\"  \n",
    "  width=\"500\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62763e8e-7328-464b-8da7-44acc227f509",
   "metadata": {},
   "source": [
    "The confusion matrix is ​​in the familiar `sklearn.metrics` module. The `confusion_matrix()` function takes correct answers and predictions as input and returns an error matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b2abd0-3e2d-43af-b80b-25537182b4fc",
   "metadata": {},
   "source": [
    "# Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6dacd9-dd3e-472c-96a5-c56536c92295",
   "metadata": {},
   "source": [
    "The error matrix will help you build new metrics. Let's start with recall.\n",
    "\n",
    "Completeness reveals what proportion of positive responses the model identified among all responses. They are usually worth their weight in gold, and it is important to understand how well the model finds them.\n",
    "\n",
    "Recall is calculated using the following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ae516-6c03-4f2c-a017-22e6c2777e97",
   "metadata": {},
   "source": [
    "<img src=\"./pict/16.png\"  \n",
    "  width=\"700\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fe2d99-c827-4e7c-bd28-da6f0b3f628c",
   "metadata": {},
   "source": [
    "Recall is the proportion of TP responses among all that have a true label of 1. It’s good when the recall value is close to one: the model is good at finding positive objects. If it’s closer to zero, the model needs to be rechecked and repaired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce50f612-71d2-4ab8-b8e8-955ee9e9d4a6",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a315d9-f65f-41df-a535-27ad4b367d63",
   "metadata": {},
   "source": [
    "Precision measures how many negative answers the model found while searching for positive ones. The more negative ones, the lower the accuracy.\n",
    "\n",
    "Precision is calculated using the following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a60e84-7687-4e1d-a64f-8b426a084320",
   "metadata": {},
   "source": [
    "<img src=\"./pict/17.png\"  \n",
    "  width=\"700\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd467184-a0b0-455e-9ad1-23f3ff13317f",
   "metadata": {},
   "source": [
    "Recall that TP is true positive responses. FP—positive responses marked by the model. We need an accuracy close to unity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25916a-ec85-471e-b2dc-78a385f92b85",
   "metadata": {},
   "source": [
    "# Precision vs. recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6474c48-0e44-47b1-96d4-df15576e2d78",
   "metadata": {},
   "source": [
    "When a model predicts positive classes poorly, both precision and recall are low. Is it possible to increase their values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a651e9-7758-4ecf-b39f-69ae787e6aec",
   "metadata": {},
   "source": [
    "<img src=\"./pict/17.jpg\"  \n",
    "  width=\"600\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3970f9e9-c4dd-40c8-872f-015a53220b8d",
   "metadata": {},
   "source": [
    "If the key metric in a problem is Recall, how can you make it as high as possible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a023b5f2-2fe3-4485-8dc3-343ca69b405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "total_row = 1000\n",
    "\n",
    "# Matrix\n",
    "#  230  170 \n",
    "#  200  400\n",
    "\n",
    "tn = 230\n",
    "fp = 170\n",
    "fn = 200\n",
    "tp = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0830337a-9576-4e62-899e-9a139c1141a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (tn + tp) / total_row\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9449652d-a29b-471b-9f81-510273d6344f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = tp / (tp + fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e03766cc-8746-469f-9e92-a51dae27d66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7017543859649122"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tp / (tp + fp)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a6e796b-362e-45da-9952-3637b192b6bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn = 500\n",
    "fp = 0\n",
    "fn = 0\n",
    "tp = 500\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50656b6e-95a6-4e58-bd92-5ef6291dada2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Обучите модель, которая отвечает «1» на все объекты. Полнота будет равна 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0da1f-e3d1-4583-8e35-11d5e313468e",
   "metadata": {},
   "source": [
    "We've covered the Recall, but how can we achieve high Precision?\n",
    "\n",
    "The formula only takes into account errors for the positive class, not the negative one. It is necessary to train a model that, on the contrary, answers “1” as rarely as possible.\n",
    "\n",
    "`But you shouldn’t answer everything with “0”, otherwise you won’t be able to “hack” the metric: in the formula, zero will be divided by zero.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c72ff-2305-4ef7-9946-99437a753cb1",
   "metadata": {},
   "source": [
    "# F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b676f86-c85b-4f50-9746-ed2ca8f3e4b8",
   "metadata": {},
   "source": [
    "Separately, completeness and accuracy are not very informative. It is necessary to simultaneously increase the performance of both. Or turn to a new metric that will unite them.\n",
    "\n",
    "Completeness and accuracy evaluate the quality of a positive class forecast from different perspectives. Recall describes how well the model understood the features of this class and recognized it. Precision detects whether the model is overdoing it by assigning positive labels.\n",
    "\n",
    "Both metrics are important. Aggregating metrics, one of which is F1-score, help control them in parallel. This is the harmonic mean of completeness and accuracy. A one in F1 means that the ratio of recall to precision is 1:1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d400e1-3b26-49bc-a7cd-4d81fc0bebce",
   "metadata": {},
   "source": [
    "<img src=\"./pict/18.png\"  \n",
    "  width=\"700\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baf0de9-8255-4ecd-a596-b859b045541a",
   "metadata": {},
   "source": [
    "<b>Important:</b> when the Recall or Precision is close to zero, then the harmonic mean itself approaches 0.\n",
    "\n",
    "The graph shows the F1-measure values at different values of precision and recall. Blue corresponds to zero, and yellow to one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e66e0f-b841-4d37-b333-e885e4cb8c86",
   "metadata": {},
   "source": [
    "<img src=\"./pict/19.png\"  \n",
    "  width=\"500\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502621b-c5ad-4e93-a8e7-b5d3ad127add",
   "metadata": {},
   "source": [
    "# Unbalanced classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25afe2db-b521-4c67-a66a-f80d1d87db85",
   "metadata": {},
   "source": [
    "Machine learning algorithms consider all objects in the training set to be equal by default. If it is important to indicate that some objects are more important, their class is assigned a weight (class_weight).\n",
    "\n",
    "The logistic regression algorithm in the `sklearn` library has a `class_weight` argument. By default it is `None`, i.e. the classes are equivalent:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35376dfe-bd88-46c7-ac13-029aab44fc0b",
   "metadata": {},
   "source": [
    "вес класса «0» = 1.0\n",
    "\n",
    "вес класса «1» = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89705e6e-9006-4e4c-be71-610ab213e524",
   "metadata": {},
   "source": [
    "If you specify `class_weight='balanced'`, the algorithm will calculate how many times class “0” is more common than class “1”.\n",
    "\n",
    "Let's denote this number N (an unknown number of times). The new class weights look like this:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91b183bc-8931-4a84-82e8-67d13563d089",
   "metadata": {},
   "source": [
    "вес класса «0» = 1.0\n",
    "\n",
    "вес класса «1» = N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8127784-4eb3-4fa7-8f56-3909b5b9b85c",
   "metadata": {},
   "source": [
    "The rare class will have more weight.\n",
    "\n",
    "Decision tree and random forest also have a `class_weight` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9b679b-032e-4d26-b2de-483eca773cd8",
   "metadata": {},
   "source": [
    "## Increasing the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72fa5c-3daa-4d80-a944-fc3a370530df",
   "metadata": {},
   "source": [
    "How to make objects of a rare class not so rare in the data?\n",
    "\n",
    "Now in the test you get 1 point for solving any problem. The most important tasks are repeated several times to make them easier to remember.\n",
    "\n",
    "When training models, this technique is called `upsampling`.\n",
    "\n",
    "The transformation takes place in several stages:\n",
    "- Divide the training sample into negative and positive objects;\n",
    "- Copy positive objects several times;\n",
    "- Taking into account the received data, create a new training sample;\n",
    "\n",
    "Mix up the data: Repeating the same questions one after another will not help learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a351f87-f43b-43af-b006-75e93c39891e",
   "metadata": {},
   "source": [
    "Python's list multiplication syntax can help you copy objects multiple times. To repeat the elements of a list, it is multiplied by a number (the required number of times):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd5ca144-fa1c-4aa1-b26a-9c4beb0a26dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0]\n",
      "[0, 1, 0, 0, 1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "answers = [0, 1, 0]\n",
    "print(answers)\n",
    "\n",
    "answers_x3 = answers * 3\n",
    "print(answers_x3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66277e8f-245e-472e-b08b-3b3b8901e8c1",
   "metadata": {},
   "source": [
    "## Reducing the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa73d8d3-f3d9-48bd-8942-efbc7e2ade4c",
   "metadata": {},
   "source": [
    "How to make objects of a frequent class less frequent?\n",
    "\n",
    "Instead of repeating important questions, remove some of the unimportant ones. This can be done using the `downsampling` technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0056be8-7a90-4e63-a82c-98f0d6f8d9ad",
   "metadata": {},
   "source": [
    "The transformation takes place in several stages:\n",
    "    \n",
    "- Divide the training sample into negative and positive objects;\n",
    "- Randomly discard some of the negative objects;\n",
    "- Taking into account the received data, create a new training sample;\n",
    "\n",
    "Shuffle the data. Positive ones should not follow negative ones: it will be more difficult for algorithms to learn."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a76888e-cd2a-463d-8c26-fe5900793d5e",
   "metadata": {},
   "source": [
    "features_sample = features_train.sample(frac=0.1, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32975e90-1a60-465b-98bb-f01a72cec1fa",
   "metadata": {},
   "source": [
    "## Classification threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793f020-b2d2-4e05-95c3-e36c00936d1f",
   "metadata": {},
   "source": [
    "What's the best way to train logistic regression? Let's see what's inside her.\n",
    "\n",
    "To determine the answer, logistic regression calculates which class an object is close to, then compares the result to zero. For convenience, we translate proximity to classes into class probability: the model tries to estimate how likely a particular class is.\n",
    "\n",
    "We have only two classes (zero and one). Class “1” probability is enough for us. The number will be from zero to one: if more than 0.5 - the object is positive, less - negative.\n",
    "\n",
    "The boundary where the negative class ends and the positive one begins is called the threshold. By default it is 0.5, but what if you change it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f6a04-1a21-446e-9ae7-febeaa252b36",
   "metadata": {},
   "source": [
    "How will precision and recall change if the threshold is reduced from 0.5 to 0.2?\n",
    "\n",
    "`The Precision will decrease, but the Recall will increase` why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5786c237-09f2-4a92-80cc-68b9f91c8d2d",
   "metadata": {},
   "source": [
    "## Changing the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20bfb59-98c4-428b-ba9f-b313cf5ea61a",
   "metadata": {},
   "source": [
    "In the `sklearn` library, class probabilities are calculated by the `predict_proba()` function. It receives object attributes as input and returns probabilities:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fb7647b-3b97-46c5-b023-8d9cea4f2a2c",
   "metadata": {},
   "source": [
    "probabilities = model.predict_proba(features) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adfd95-7903-4640-b05c-eaa3dc41173b",
   "metadata": {},
   "source": [
    "# PR curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e172f7-26b7-4636-a858-4e1882986258",
   "metadata": {},
   "source": [
    "Let's plot what the metric values look like when the threshold changes.\n",
    "\n",
    "The accuracy value is plotted vertically on the graph, and recall value is plotted horizontally.\n",
    "\n",
    "The curve showing their values is called the PR curve. The higher the curve, the better the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1012c51-b918-432d-a2ce-2fac83283d0b",
   "metadata": {},
   "source": [
    "<img src=\"./pict/20.png\"  \n",
    "  width=\"500\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66467c-e72c-4d8c-827b-199e64f8fdb8",
   "metadata": {},
   "source": [
    "# TPR и FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d93e68-766f-4fc2-939a-2c7f4dc577dc",
   "metadata": {},
   "source": [
    "When there are no positive objects, the accuracy cannot be calculated. Let's choose other characteristics in which there is no division by zero.\n",
    "\n",
    "Before moving on to the new curve, let's give a few important definitions.\n",
    "\n",
    "How to measure how correctly a classifier finds objects? Proportion of correctly predicted objects to the total number of objects in the class. This relationship is called\n",
    "\n",
    "`TPR` (True Positive Rate) or recall. The formula looks like this, where `P=TP+FN`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4960c85f-2cc0-4dde-9eb6-22a94d4102ee",
   "metadata": {},
   "source": [
    "<img src=\"./pict/21.png\"  \n",
    "  width=\"700\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c0f880-e264-4007-8f7b-3e5d108d19c1",
   "metadata": {},
   "source": [
    "The proportion of false positives to the total number of objects outside the class (False Positive Rate, `FPR`) is calculated similarly.\n",
    "\n",
    "This is the ratio of `FP responses` (False Positives - negatives classified as positive) to the sum of negative responses:\n",
    "\n",
    "`FP` and `TN` (True Negatives - correctly classified negative responses). Below is the formula where `N=FP+TN`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae30ef-4d06-4721-a04d-b754e38c33c1",
   "metadata": {},
   "source": [
    "<img src=\"./pict/22.png\"  \n",
    "  width=\"700\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc52f95-a82d-4075-8d12-7bdaf26111d0",
   "metadata": {},
   "source": [
    "There will be no division by zero: the denominators contain values ​​that are constant and do not depend on changes in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea947198-730d-47c1-b63c-769bc4fc0ad5",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51db3696-a26f-40a1-8fbc-b72d4949ba79",
   "metadata": {},
   "source": [
    "We have witnessed a new confrontation - `TPR` versus `FPR`. Let's depict it on a graph.\n",
    "\n",
    "We plot the proportion of false positive responses (`FPR`) horizontally, and the proportion of true positive responses (`TPR`) vertically. Let's go through the values ​​of the logistic regression threshold and draw a curve.\n",
    "\n",
    "It is called the `ROC curve`, or `error curve` (receiver operating characteristic; the term comes from signal processing theory).\n",
    "\n",
    "For a model that always responds at random, the `ROC curve` looks like a straight line going from the bottom left to the top right. The higher the graph, the higher the `TPR` value and the better the quality of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35402c2a-da5d-4e8f-b71f-ccb71680047b",
   "metadata": {},
   "source": [
    "<img src=\"./pict/23.png\"  \n",
    "  width=\"500\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be2504-cab5-49fd-b4c0-28bf0c649a10",
   "metadata": {},
   "source": [
    "To identify how much our model differs from a random one, let’s calculate the area under the ROC curve - `AUC-ROC` (Area Under Curve ROC). This is a new quality metric that ranges from 0 to 1. The `AUC-ROC` of the random model is 0.5.\n",
    "\n",
    "The `roc_curve()` function from the `sklearn.metrics` module will help you build a ROC curve:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10874120-1441-45c3-bdd1-357f39196f1a",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_curve "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a2b368-027a-44ab-a192-04acd7f920d2",
   "metadata": {},
   "source": [
    "It takes as input the values of the target feature and the probability of the positive class. Iterates through different thresholds and returns three lists: `FPR` values, `TPR` values and `considered thresholds`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0052661f-7f42-447f-b970-89acd61e69f1",
   "metadata": {},
   "source": [
    "fpr, tpr, thresholds = roc_curve(target, probabilities) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eacd007-8847-40a5-b6c3-608714e43941",
   "metadata": {},
   "source": [
    "# MSE/RMSE in a regression task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5899190e-04b4-4176-ae19-fda5d55d95fc",
   "metadata": {},
   "source": [
    "Which metric is best suited for regression tasks? MSE is the mean square error. But how do you understand what the model thinks is correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29838e44-f836-48d9-92a8-43117d40aa7e",
   "metadata": {},
   "source": [
    "<font size=\"5\">  \n",
    "    MSE = sum of squared object errors / number of object\n",
    "</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25ecd0-b8a7-495d-a26d-de5036b30e59",
   "metadata": {},
   "source": [
    "<img src=\"./pict/9.png\"  \n",
    "  width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91300be-22f2-4bbc-9892-82d83b3c560b",
   "metadata": {},
   "source": [
    "Один из простых способов это посмотреть адекватность модели (сравнить значения с средним) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34892590-cf92-4aa3-8fdf-c19f44d1cc3a",
   "metadata": {},
   "source": [
    "<img src=\"./pict/24.png\"  \n",
    "  width=\"700\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3bcf0-35c2-4dcd-9247-d62c9e84a15d",
   "metadata": {},
   "source": [
    "# Coefficient of determination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75e057-a3d1-4e40-af70-a451d4bd283b",
   "metadata": {},
   "source": [
    "To avoid having to constantly compare the model with the average, we introduce a new metric. It is expressed not in absolute values, but in relative ones.\n",
    "\n",
    "The `coefficient of determination`, or `R2 metric` (coefficient of determination; R-squared), calculates the proportion of the model's mean squared error from the MSE of the mean, and then subtracts this value from unity. An increase in the metric means an increase in the quality of the model.\n",
    "The formula for calculating R2 looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b7378-49a7-4b8a-b3ce-545162a57603",
   "metadata": {},
   "source": [
    "<img src=\"./pict/25.png\"  \n",
    "  width=\"700\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9f950-8879-43be-a650-4b1d5672f8f5",
   "metadata": {},
   "source": [
    "- The value of the R2 metric is equal to one only in one case, if MSE is zero. This model predicts all answers perfectly.\n",
    "- R2 is zero: the model performs the same as the average.\n",
    "- If the R2 metric is negative, the quality of the model is very low.\n",
    "- The value of R2 cannot be greater than one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe61b78-bdbe-4842-a7f3-ffa497af9e0b",
   "metadata": {},
   "source": [
    "# Mean absolute deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547fd48-fb31-423c-927b-799a1f49c053",
   "metadata": {},
   "source": [
    "Let's get acquainted with the new quality metric - `MAE` (mean absolute error). It is similar to MSE, but does not have squaring\n",
    "\n",
    "Let's write the new metric in symbols, not words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a9cc40-4787-41ba-ad4a-107021efec95",
   "metadata": {},
   "source": [
    "<img src=\"./pict/26.png\"  \n",
    "  width=\"400\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be3282-7e58-4e84-8b84-e6141f12e00b",
   "metadata": {},
   "source": [
    "1. The value of the target feature for an object with serial number `i` in the sample on which the quality is measured. For example, test. The letter `y` is associated with the target feature. The subscript indicates the object number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f73f79-5922-4038-ab7b-0351c5d82e19",
   "metadata": {},
   "source": [
    "<img src=\"./pict/27.png\"  \n",
    "  width=\"400\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e3732b-2563-4238-8fbd-5f1dc8ebe5f2",
   "metadata": {},
   "source": [
    "2. Prediction value for an object with serial number `i`, for example, in the test sample. The `circumflexus` sign above the `y` indicates that this is a model prediction and not the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ec8b02-7100-4d29-969c-b4a3657821db",
   "metadata": {},
   "source": [
    "Object deviation is the difference between the value of the target feature and the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110155a-314a-45db-8a06-f06f79e349e2",
   "metadata": {},
   "source": [
    "To get rid of the difference between underestimation and overestimation in the new metric, the `absolute deviation` is calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0217a4c4-3100-4493-b49d-e6a49b3a7a6b",
   "metadata": {},
   "source": [
    "To collect deviations for the entire sample, we add the following notation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3e554-08cd-47a1-8b9c-953319124ef6",
   "metadata": {},
   "source": [
    "<img src=\"./pict/28.png\"  \n",
    "  width=\"400\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c0830c-5d0d-41b0-bdca-d179521c3c3d",
   "metadata": {},
   "source": [
    "3. Number of objects in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2431e7-32d8-4511-9d3c-7f3224902170",
   "metadata": {},
   "source": [
    "<img src=\"./pict/29.png\"  \n",
    "  width=\"400\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d621d-04e2-4752-ac58-ace9c46630b6",
   "metadata": {},
   "source": [
    "4. Summation over all sample objects (i varies from 1 to N)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d7fd8-6bc5-414f-85b4-1e69323602d4",
   "metadata": {},
   "source": [
    "This brings us to the `mean absolute deviation`, or `MAE` formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa41786f-ac59-433b-b0df-06232bcba5bb",
   "metadata": {},
   "source": [
    "<img src=\"./pict/30.png\"  \n",
    "  width=\"700\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa5079-91c6-42a0-9780-fbe2c6b317e4",
   "metadata": {},
   "source": [
    "# MAE interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb53a5-d712-4528-a4ce-77d706c970bb",
   "metadata": {},
   "source": [
    "To calculate MSE, we took the average value as a constant. But is it suitable for calculating MAE? Let's figure it out.\n",
    "\n",
    "The constant model is chosen so that the value of the MAE metric is extremely low. We need to find the value of `a` that achieves the minimum:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8acd74-3d2f-49b0-8de0-4102668f641d",
   "metadata": {},
   "source": [
    "<img src=\"./pict/31.png\"  \n",
    "  width=\"700\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f146bc1-0967-406b-9fd5-e7d3fb7030b0",
   "metadata": {},
   "source": [
    "The minimum is obtained when `a` is equal to the `median` of the target feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f65802-0305-436d-9ac8-b186b9a450be",
   "metadata": {},
   "source": [
    "# Impact of scatter on metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af276b0f-74c5-4e34-8603-187a6ea9dba2",
   "metadata": {},
   "source": [
    "Let's consider how MAE and RMSE depend on the spread of the target feature.\n",
    "\n",
    "Unlike MAE, the RMSE metric is more sensitive to large values: significant errors greatly affect the final value of the square root of the mean square error.\n",
    "\n",
    "Here are three graphs of error distribution (the horizontal graph shows the error values, and the vertical graph shows their number):\n",
    "    \n",
    "1. The first one has an equal number of small (from 0 to 10) and large (40 and above) errors.\n",
    "2. In the second and third graphs, the gap gradually increases. Very big errors appear, and more small ones appear. MAE values ​​do not change: large errors are compensated by small ones. But RMSE is increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2cc9ed-142a-45ca-a16d-f1fd767b12ca",
   "metadata": {},
   "source": [
    "<img src=\"./pict/33.jpg\"  \n",
    "  width=\"700\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d130a-9c66-4b31-bac2-13315eceb96c",
   "metadata": {},
   "source": [
    "Now you know that you can change the value of one metric without changing another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef83ca-a770-440f-aa42-48163529ea29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
